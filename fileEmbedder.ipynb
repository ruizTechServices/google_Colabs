{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "12371f66",
        "a9120c52",
        "0d87c1b7"
      ],
      "authorship_tag": "ABX9TyNZ5y236zY9VMG7ZlEz2XyL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48f924a84d6b4318a5a41746ad7faa3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "AccordionModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "AccordionModel",
            "_titles": {
              "0": "âœ… Data Pipeline Checklist"
            },
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "AccordionView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11edbd4ade23442c8cdf44beb62db5f3"
            ],
            "layout": "IPY_MODEL_327f11e000d647ea8d88d5bebb0c1ee5",
            "selected_index": 0
          }
        },
        "11edbd4ade23442c8cdf44beb62db5f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_241a46efa38f43f3ae88a660fd77fa7d",
              "IPY_MODEL_943cb8e89ed9480a9544e838211b3f6f",
              "IPY_MODEL_f276cdaf01c648a2ae571e8760f9b078",
              "IPY_MODEL_c21f023b5495493e96d8f44c42f1c02f",
              "IPY_MODEL_f889368bec5b4f32a657141ee2ca6436",
              "IPY_MODEL_4cb75374aea74de5b509674ab40d13a7",
              "IPY_MODEL_6800527985df484cbca7867718fae837",
              "IPY_MODEL_ee9d82e7feca417dbc00be9ab9d208ac",
              "IPY_MODEL_becbb54209c84d16a53156ea1a718f7a",
              "IPY_MODEL_20d7dbb3b7fc45b394dca72f08494e52",
              "IPY_MODEL_76b4a8899f2d41b4985aacc2a49d19c0",
              "IPY_MODEL_71cb199624bc446a80d22dfacc0bebf7",
              "IPY_MODEL_5c87fa27340046d48ba89f5555b11149",
              "IPY_MODEL_b2d834e3d0b54a8988a92fc02a7260bd"
            ],
            "layout": "IPY_MODEL_665969e5d80b4516b006a19a3563ae57"
          }
        },
        "327f11e000d647ea8d88d5bebb0c1ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "241a46efa38f43f3ae88a660fd77fa7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Create/Open this Colab notebook",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_413ac11f07f144848685cd0a41d78b5b",
            "style": "IPY_MODEL_c4d54eaaffb84eb79e2e5b0ee5e82511",
            "value": true
          }
        },
        "943cb8e89ed9480a9544e838211b3f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Install Python deps",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_e83a637e1e90481381b52920556dd2e0",
            "style": "IPY_MODEL_5d925548e4e9425489a67e12be431af3",
            "value": true
          }
        },
        "f276cdaf01c648a2ae571e8760f9b078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Set API keys (OPENAI_API_KEY or GOOGLE_API_KEY; optional OLLAMA via ngrok)",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_cb667a07fd1649a1a3eb9b0176242a61",
            "style": "IPY_MODEL_cf79790d65214f0c9e6ccada59b88d47",
            "value": true
          }
        },
        "c21f023b5495493e96d8f44c42f1c02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Decide providers: LLM for context (OpenAI Mini or Ollama) & Embeddings (OpenAI or Google)",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_38d1aebb80454b52b58bea76c168943f",
            "style": "IPY_MODEL_b8e98d3aa5b54d83bfa5784a4084273e",
            "value": false
          }
        },
        "f889368bec5b4f32a657141ee2ca6436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Upload sample files",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_fd8333678a094f63adda531760d6d0bd",
            "style": "IPY_MODEL_ca9e5b8aa6fe4a239a8a62672d5ddb06",
            "value": false
          }
        },
        "4cb75374aea74de5b509674ab40d13a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Normalize files to text",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_b9d68d3f054f4f57ac5c373147477587",
            "style": "IPY_MODEL_b1feab97bf094026a7adc1963ea5838d",
            "value": false
          }
        },
        "6800527985df484cbca7867718fae837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Chunk text by tokens",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_653e51651e8a45749ea0ce4b8f17c160",
            "style": "IPY_MODEL_122110035e524097a85df29c287a8860",
            "value": false
          }
        },
        "ee9d82e7feca417dbc00be9ab9d208ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Run optional context analysis",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_858458837716405ca9b0b28cd8932390",
            "style": "IPY_MODEL_411a34d5413e41a289ad1070c135cb7e",
            "value": false
          }
        },
        "becbb54209c84d16a53156ea1a718f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Generate embeddings",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_9c70fd48dbcf4ea3991f11c04cd09210",
            "style": "IPY_MODEL_be926367139a4b87981c33d51dee02a9",
            "value": false
          }
        },
        "20d7dbb3b7fc45b394dca72f08494e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Save JSONL/Parquet dataset",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_cd5afd30efd946c4b50f59346d9d9f3d",
            "style": "IPY_MODEL_2f9c02a98b0c4da4b0c9a2b594f739cc",
            "value": false
          }
        },
        "76b4a8899f2d41b4985aacc2a49d19c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Download artifacts (or mount Drive)",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_2218ee496af3496388f3e61bd29f8b75",
            "style": "IPY_MODEL_6f9fdffd3de846599b3d6f56eb21e942",
            "value": false
          }
        },
        "71cb199624bc446a80d22dfacc0bebf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Document next steps (vector DB, fine-tuning, RAG)",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_7986640804b445e2a5d447e9a1de1460",
            "style": "IPY_MODEL_0155af3474b347e681d357b050c1df0b",
            "value": false
          }
        },
        "5c87fa27340046d48ba89f5555b11149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Save progress",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a128848e58cd4764b16e3c43d6855ca2",
            "style": "IPY_MODEL_9fea7f41e5f34e9d8e3a165c0fccf3ea",
            "tooltip": ""
          }
        },
        "b2d834e3d0b54a8988a92fc02a7260bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01644d8065534ceaba407223e581bc0e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c80ef11dceec4e9091c886404a0d0b0a",
            "value": "Saved at 2025-09-07T21:03:53.750514Z"
          }
        },
        "665969e5d80b4516b006a19a3563ae57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413ac11f07f144848685cd0a41d78b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d54eaaffb84eb79e2e5b0ee5e82511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e83a637e1e90481381b52920556dd2e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d925548e4e9425489a67e12be431af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb667a07fd1649a1a3eb9b0176242a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf79790d65214f0c9e6ccada59b88d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38d1aebb80454b52b58bea76c168943f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8e98d3aa5b54d83bfa5784a4084273e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd8333678a094f63adda531760d6d0bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9e5b8aa6fe4a239a8a62672d5ddb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9d68d3f054f4f57ac5c373147477587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1feab97bf094026a7adc1963ea5838d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "653e51651e8a45749ea0ce4b8f17c160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122110035e524097a85df29c287a8860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "858458837716405ca9b0b28cd8932390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "411a34d5413e41a289ad1070c135cb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c70fd48dbcf4ea3991f11c04cd09210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be926367139a4b87981c33d51dee02a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd5afd30efd946c4b50f59346d9d9f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f9c02a98b0c4da4b0c9a2b594f739cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2218ee496af3496388f3e61bd29f8b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f9fdffd3de846599b3d6f56eb21e942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7986640804b445e2a5d447e9a1de1460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0155af3474b347e681d357b050c1df0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a128848e58cd4764b16e3c43d6855ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fea7f41e5f34e9d8e3a165c0fccf3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "01644d8065534ceaba407223e581bc0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c80ef11dceec4e9091c886404a0d0b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruizTechServices/google_Colabs/blob/main/fileEmbedder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How do I create a Small Language Model that I can host anywhere at all in any digital device?"
      ],
      "metadata": {
        "id": "K6T_Ptkn05ii"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0qsp-A001xo",
        "outputId": "e57ee977-f26a-44f5-aea5-2e86a7b4f8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.11\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xz0_TzD7Wwi",
        "outputId": "92d064ea-beb1-4d9d-c82f-e453984c6037"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Project Checklist (click to expand)\n",
        "# @markdown Check items as you complete them. State is saved to /content/todo_data.json\n",
        "from IPython.display import display\n",
        "import ipywidgets as w, json, os, datetime\n",
        "\n",
        "STORE = \"/content/todo_data.json\"\n",
        "DEFAULTS = [\n",
        "  \"Create/Open this Colab notebook\",\n",
        "  \"Install Python deps\",\n",
        "  \"Set API keys (OPENAI_API_KEY or GOOGLE_API_KEY; optional OLLAMA via ngrok)\",\n",
        "  \"Decide providers: LLM for context (OpenAI Mini or Ollama) & Embeddings (OpenAI or Google)\",\n",
        "  \"Upload sample files\",\n",
        "  \"Normalize files to text\",\n",
        "  \"Chunk text by tokens\",\n",
        "  \"Run optional context analysis\",\n",
        "  \"Generate embeddings\",\n",
        "  \"Save JSONL/Parquet dataset\",\n",
        "  \"Download artifacts (or mount Drive)\",\n",
        "  \"Document next steps (vector DB, fine-tuning, RAG)\"\n",
        "]\n",
        "\n",
        "if os.path.exists(STORE):\n",
        "  state = json.load(open(STORE))\n",
        "  items = state.get(\"items\", DEFAULTS)\n",
        "  checks = state.get(\"checks\", [False]*len(items))\n",
        "else:\n",
        "  items = DEFAULTS[:]\n",
        "  checks = [False]*len(items)\n",
        "\n",
        "boxes = []\n",
        "for i, label in enumerate(items):\n",
        "  cb = w.Checkbox(value=checks[i], description=label)\n",
        "  boxes.append(cb)\n",
        "\n",
        "def save_state(_=None):\n",
        "  payload = {\n",
        "    \"items\": [b.description for b in boxes],\n",
        "    \"checks\": [b.value for b in boxes],\n",
        "    \"saved_at\": datetime.datetime.utcnow().isoformat() + \"Z\"\n",
        "  }\n",
        "  json.dump(payload, open(STORE, \"w\"))\n",
        "  status.value = f\"Saved at {payload['saved_at']}\"\n",
        "\n",
        "btn = w.Button(description=\"Save progress\", button_style=\"success\")\n",
        "btn.on_click(save_state)\n",
        "status = w.HTML(value=\"\")\n",
        "\n",
        "accordion = w.Accordion(children=[w.VBox(boxes+[btn, status])])\n",
        "accordion.set_title(0, \"âœ… Data Pipeline Checklist\")\n",
        "display(accordion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593,
          "referenced_widgets": [
            "48f924a84d6b4318a5a41746ad7faa3a",
            "11edbd4ade23442c8cdf44beb62db5f3",
            "327f11e000d647ea8d88d5bebb0c1ee5",
            "241a46efa38f43f3ae88a660fd77fa7d",
            "943cb8e89ed9480a9544e838211b3f6f",
            "f276cdaf01c648a2ae571e8760f9b078",
            "c21f023b5495493e96d8f44c42f1c02f",
            "f889368bec5b4f32a657141ee2ca6436",
            "4cb75374aea74de5b509674ab40d13a7",
            "6800527985df484cbca7867718fae837",
            "ee9d82e7feca417dbc00be9ab9d208ac",
            "becbb54209c84d16a53156ea1a718f7a",
            "20d7dbb3b7fc45b394dca72f08494e52",
            "76b4a8899f2d41b4985aacc2a49d19c0",
            "71cb199624bc446a80d22dfacc0bebf7",
            "5c87fa27340046d48ba89f5555b11149",
            "b2d834e3d0b54a8988a92fc02a7260bd",
            "665969e5d80b4516b006a19a3563ae57",
            "413ac11f07f144848685cd0a41d78b5b",
            "c4d54eaaffb84eb79e2e5b0ee5e82511",
            "e83a637e1e90481381b52920556dd2e0",
            "5d925548e4e9425489a67e12be431af3",
            "cb667a07fd1649a1a3eb9b0176242a61",
            "cf79790d65214f0c9e6ccada59b88d47",
            "38d1aebb80454b52b58bea76c168943f",
            "b8e98d3aa5b54d83bfa5784a4084273e",
            "fd8333678a094f63adda531760d6d0bd",
            "ca9e5b8aa6fe4a239a8a62672d5ddb06",
            "b9d68d3f054f4f57ac5c373147477587",
            "b1feab97bf094026a7adc1963ea5838d",
            "653e51651e8a45749ea0ce4b8f17c160",
            "122110035e524097a85df29c287a8860",
            "858458837716405ca9b0b28cd8932390",
            "411a34d5413e41a289ad1070c135cb7e",
            "9c70fd48dbcf4ea3991f11c04cd09210",
            "be926367139a4b87981c33d51dee02a9",
            "cd5afd30efd946c4b50f59346d9d9f3d",
            "2f9c02a98b0c4da4b0c9a2b594f739cc",
            "2218ee496af3496388f3e61bd29f8b75",
            "6f9fdffd3de846599b3d6f56eb21e942",
            "7986640804b445e2a5d447e9a1de1460",
            "0155af3474b347e681d357b050c1df0b",
            "a128848e58cd4764b16e3c43d6855ca2",
            "9fea7f41e5f34e9d8e3a165c0fccf3ea",
            "01644d8065534ceaba407223e581bc0e",
            "c80ef11dceec4e9091c886404a0d0b0a"
          ]
        },
        "cellView": "form",
        "id": "J-sWtOlM1GmK",
        "outputId": "8c72e5f1-0dc4-4567-d269-edc3e81012fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Accordion(children=(VBox(children=(Checkbox(value=False, description='Create/Open this Colab notebook'), Checkâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48f924a84d6b4318a5a41746ad7faa3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1855831588.py:39: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"saved_at\": datetime.datetime.utcnow().isoformat() + \"Z\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pypdf python-docx html2text beautifulsoup4 tiktoken pandas pyarrow openai google-generativeai tqdm\n"
      ],
      "metadata": {
        "id": "gHNrLqcN7rHk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ---- Choose providers ----\n",
        "LLM_FOR_CONTEXT = \"openai\"   # options: \"openai\", \"ollama\", \"none\"\n",
        "EMBED_PROVIDER  = \"openai\"   # options: \"openai\", \"google\"\n",
        "\n",
        "# ---- Keys (assume they already exist; just set in the environment in Colab UI) ----\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"...\"       # set in Colab > three-dots > Variables (recommended)\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = \"...\"\n",
        "\n",
        "# ---- Ollama via ngrok (optional). Example: \"https://user:pass-yourname.ngrok-free.app\"\n",
        "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\", \"\").strip()\n",
        "\n",
        "# ---- Chunking knobs ----\n",
        "CHUNK_TOKENS   = 800\n",
        "CHUNK_OVERLAP  = 200\n",
        "\n",
        "# ---- Embedding model names (safe defaults) ----\n",
        "OPENAI_EMBED_MODEL  = \"text-embedding-3-small\"  # solid accuracy, good price\n",
        "GOOGLE_EMBED_MODEL  = \"text-embedding-004\"      # current public model name; adjust if Google updates\n",
        "\n",
        "# ---- LLM for analysis (fast & cheap default) ----\n",
        "OPENAI_MINI_MODEL = \"gpt-4o-mini\"               # swap if you prefer o3-mini or similar\n",
        "OLLAMA_MODEL      = \"llama3.1\"                  # choose your local model tag\n",
        "\n",
        "print(\"Configured:\", {\"LLM_FOR_CONTEXT\": LLM_FOR_CONTEXT, \"EMBED_PROVIDER\": EMBED_PROVIDER})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3X4o7a78AdF",
        "outputId": "1fc86fc0-a1b9-4926-a432-1c70213ab2e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configured: {'LLM_FOR_CONTEXT': 'openai', 'EMBED_PROVIDER': 'openai'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os, shutil, pathlib\n",
        "\n",
        "UPLOAD_DIR = \"/content/uploads\"\n",
        "pathlib.Path(UPLOAD_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Select one or more filesâ€¦\")\n",
        "up = files.upload()\n",
        "for name, data in up.items():\n",
        "    with open(os.path.join(UPLOAD_DIR, name), \"wb\") as f:\n",
        "        f.write(data)\n",
        "print(\"Saved to\", UPLOAD_DIR, \"->\", os.listdir(UPLOAD_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "AECWajcn8DbF",
        "outputId": "7e27f542-07d7-48b2-a840-26e0e33ec7a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select one or more filesâ€¦\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a5709645-2977-4d41-baa0-1f60096136b2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a5709645-2977-4d41-baa0-1f60096136b2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1-bitLLMs.pdf to 1-bitLLMs.pdf\n",
            "Saved to /content/uploads -> ['1-bitLLMs.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib, re\n",
        "from pypdf import PdfReader\n",
        "import docx\n",
        "from bs4 import BeautifulSoup\n",
        "import html2text\n",
        "\n",
        "def read_pdf(path: str) -> str:\n",
        "    out = []\n",
        "    try:\n",
        "        pdf = PdfReader(path)\n",
        "        for p in pdf.pages:\n",
        "            out.append(p.extract_text() or \"\")\n",
        "    except Exception as e:\n",
        "        print(f\"[PDF ERROR] {path} -> {e}\")\n",
        "    return \"\\n\".join(out)\n",
        "\n",
        "def read_docx(path: str) -> str:\n",
        "    try:\n",
        "        d = docx.Document(path)\n",
        "        return \"\\n\".join([p.text for p in d.paragraphs])\n",
        "    except Exception as e:\n",
        "        print(f\"[DOCX ERROR] {path} -> {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def read_html(path: str) -> str:\n",
        "    try:\n",
        "        html = pathlib.Path(path).read_text(errors=\"ignore\")\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "        # keep visible text; fallback to markdown\n",
        "        md = html2text.html2text(str(soup))\n",
        "        return md\n",
        "    except Exception as e:\n",
        "        print(f\"[HTML ERROR] {path} -> {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def read_textlike(path: str) -> str:\n",
        "    try:\n",
        "        return pathlib.Path(path).read_text(errors=\"ignore\")\n",
        "    except Exception as e:\n",
        "        print(f\"[TEXT ERROR] {path} -> {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def to_text(path: str) -> str:\n",
        "    ext = pathlib.Path(path).suffix.lower()\n",
        "    if ext == \".pdf\":   return read_pdf(path)\n",
        "    if ext == \".docx\":  return read_docx(path)\n",
        "    if ext in (\".html\", \".htm\"): return read_html(path)\n",
        "    # csv, md, txt and others -> read as text\n",
        "    return read_textlike(path)\n",
        "\n",
        "docs = []\n",
        "for p in sorted(pathlib.Path(UPLOAD_DIR).glob(\"**/*\")):\n",
        "    if p.is_file():\n",
        "        txt = to_text(str(p))\n",
        "        txt = re.sub(r\"[ \\t]+\", \" \", txt)\n",
        "        txt = re.sub(r\"\\n{3,}\", \"\\n\\n\", txt).strip()\n",
        "        if len(txt) > 0:\n",
        "            docs.append({\"doc_id\": p.name, \"path\": str(p), \"text\": txt})\n",
        "len(docs), [d[\"doc_id\"] for d in docs][:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVVvmcPn8Yku",
        "outputId": "2ecf3879-80fa-458c-a82c-ccf358287379"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, ['1-bitLLMs.pdf'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "from typing import List, Dict\n",
        "\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")  # robust general encoder\n",
        "\n",
        "def split_by_tokens(text: str, target: int, overlap: int) -> List[str]:\n",
        "    tokens = enc.encode(text)\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        window = tokens[i : i + target]\n",
        "        chunks.append(enc.decode(window))\n",
        "        i += max(1, target - overlap)\n",
        "    return chunks\n",
        "\n",
        "records = []\n",
        "for d in docs:\n",
        "    chs = split_by_tokens(d[\"text\"], CHUNK_TOKENS, CHUNK_OVERLAP)\n",
        "    for idx, ch in enumerate(chs):\n",
        "        records.append({\n",
        "            \"id\": f\"{d['doc_id']}::{idx}\",\n",
        "            \"doc_id\": d[\"doc_id\"],\n",
        "            \"chunk_index\": idx,\n",
        "            \"text\": ch,\n",
        "            \"meta\": {\"source\": d[\"path\"]}\n",
        "        })\n",
        "\n",
        "len(records)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moaQ2yRI8_aT",
        "outputId": "f336937f-a562-47dc-f512-f8c804627ed7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, requests, math, time\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "def analyze_with_openai(texts, model=OPENAI_MINI_MODEL):\n",
        "    import openai\n",
        "    client = openai.OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "    outs = []\n",
        "    for t in texts:\n",
        "        prompt = (\n",
        "          \"Summarize this chunk in 1-2 sentences. \"\n",
        "          \"Also return 3-6 keywords and a short section title.\\n\\nCHUNK:\\n\" + t\n",
        "        )\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\":\"system\",\"content\":\"Be concise and accurate.\"},\n",
        "                      {\"role\":\"user\",\"content\":prompt}],\n",
        "            temperature=0.2,\n",
        "            max_tokens=200,\n",
        "        )\n",
        "        outs.append(resp.choices[0].message.content)\n",
        "    return outs\n",
        "\n",
        "def analyze_with_ollama(texts, model=OLLAMA_MODEL):\n",
        "    # Requires: OLLAMA_BASE_URL to be reachable (e.g., your ngrok tunnel)\n",
        "    outs = []\n",
        "    for t in texts:\n",
        "        payload = {\n",
        "          \"model\": model,\n",
        "          \"messages\": [\n",
        "            {\"role\":\"system\",\"content\":\"Be concise and accurate.\"},\n",
        "            {\"role\":\"user\",\"content\":\n",
        "              \"Summarize this chunk in 1-2 sentences. \"\n",
        "              \"Also return 3-6 keywords and a short section title.\\n\\nCHUNK:\\n\"+t}\n",
        "          ],\n",
        "          \"stream\": False\n",
        "        }\n",
        "        r = requests.post(f\"{OLLAMA_BASE_URL}/api/chat\", json=payload, timeout=120)\n",
        "        r.raise_for_status()\n",
        "        outs.append(r.json().get(\"message\", {}).get(\"content\", \"\"))\n",
        "    return outs\n",
        "\n",
        "def parse_analysis(s: str) -> dict:\n",
        "    # Accept free-form; try to split; keep it robust\n",
        "    if not s: return {\"summary\":\"\", \"keywords\":[], \"section\":\"\"}\n",
        "    lines = [x.strip() for x in s.splitlines() if x.strip()]\n",
        "    summary = lines[0] if lines else \"\"\n",
        "    # naive keyword/section extraction\n",
        "    kws = []\n",
        "    section = \"\"\n",
        "    for ln in lines[1:]:\n",
        "        low = ln.lower()\n",
        "        if \"keyword\" in low:\n",
        "            kws = [k.strip(\" ,;\") for k in ln.split(\":\")[-1].split(\",\")]\n",
        "        if \"title\" in low or \"section\" in low:\n",
        "            section = ln.split(\":\")[-1].strip()\n",
        "    return {\"summary\": summary, \"keywords\": kws, \"section\": section}\n",
        "\n",
        "if LLM_FOR_CONTEXT in (\"openai\",\"ollama\"):\n",
        "    BATCH = 16\n",
        "    for i in tqdm(range(0, len(records), BATCH)):\n",
        "        batch = records[i:i+BATCH]\n",
        "        texts = [r[\"text\"] for r in batch]\n",
        "        if LLM_FOR_CONTEXT == \"openai\":\n",
        "            outs = analyze_with_openai(texts)\n",
        "        else:\n",
        "            assert OLLAMA_BASE_URL, \"Set OLLAMA_BASE_URL to your ngrok tunnel (e.g., https://user:pass-<name>.ngrok-free.app)\"\n",
        "            outs = analyze_with_ollama(texts)\n",
        "        for r, out in zip(batch, outs):\n",
        "            r.update(parse_analysis(out))\n",
        "else:\n",
        "    print(\"Skipping context analysis.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9oeEBtP9Cid",
        "outputId": "d1de714c-4576-4dad-ab24-805423c6eacd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "\n",
        "def embed_openai(texts):\n",
        "    import openai\n",
        "    client = openai.OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "    # Batch for efficiency\n",
        "    vecs = []\n",
        "    B = 128\n",
        "    for i in tqdm(range(0, len(texts), B)):\n",
        "        sub = texts[i:i+B]\n",
        "        resp = client.embeddings.create(model=OPENAI_EMBED_MODEL, input=sub)\n",
        "        vecs.extend([np.array(d.embedding, dtype=np.float32) for d in resp.data])\n",
        "    return vecs\n",
        "\n",
        "def embed_google(texts):\n",
        "    import google.generativeai as genai\n",
        "    genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "    model = genai.embedder.GenerativeModelEmbedding(  # fallback if class evolves; API sometimes provides simple `genai.embed_content`\n",
        "        model_name=GOOGLE_EMBED_MODEL\n",
        "    ) if hasattr(genai, \"embedder\") else None\n",
        "\n",
        "    vecs = []\n",
        "    for t in tqdm(texts):\n",
        "        # API surface changes over time; this path works with most releases:\n",
        "        if hasattr(genai, \"embed_content\"):\n",
        "            out = genai.embed_content(model=GOOGLE_EMBED_MODEL, content=t)\n",
        "            vecs.append(np.array(out[\"embedding\"], dtype=np.float32))\n",
        "        else:\n",
        "            # future-proof fallback if embedder object exists\n",
        "            out = genai.embedder.embed(model=GOOGLE_EMBED_MODEL, content=t)\n",
        "            vecs.append(np.array(out[\"embedding\"], dtype=np.float32))\n",
        "    return vecs\n",
        "\n",
        "texts = [r[\"text\"] for r in records]\n",
        "if EMBED_PROVIDER == \"openai\":\n",
        "    vectors = embed_openai(texts)\n",
        "else:\n",
        "    vectors = embed_google(texts)\n",
        "\n",
        "for r, v in zip(records, vectors):\n",
        "    r[\"embedding\"] = v.tolist()\n",
        "\n",
        "len(records), len(records[0][\"embedding\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYqHUIoz9uMK",
        "outputId": "3b6d33f0-aa3e-4d33-d1b2-d717b3bf2e12"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 1536)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, pandas as pd, numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# JSONL\n",
        "jsonl_path = \"/content/dataset.jsonl\"\n",
        "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for r in records:\n",
        "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "# Parquet (store embeddings as list or fixed-length numpy array)\n",
        "df = pd.DataFrame(records)\n",
        "parquet_path = \"/content/dataset.parquet\"\n",
        "df.to_parquet(parquet_path, engine=\"pyarrow\", index=False)\n",
        "\n",
        "print(\"Wrote:\", jsonl_path, parquet_path)\n",
        "files.download(jsonl_path)\n",
        "files.download(parquet_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0rxKSUTx912d",
        "outputId": "e73447b5-6f3f-493d-b4d5-4a1fafaa56c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /content/dataset.jsonl /content/dataset.parquet\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_87b18b45-ddb9-402c-a6b9-4a7f1f8ebcb4\", \"dataset.jsonl\", 483841)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5b2f37ae-d703-4868-92c5-baef462f5438\", \"dataset.parquet\", 184418)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The previous is a comprehensive File Embedder. It turns"
      ],
      "metadata": {
        "id": "8PDWb689QAxL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12371f66"
      },
      "source": [
        "# Task --------From GOOGLE\n",
        "Load Google Drive in the selected empty cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f4edad9"
      },
      "source": [
        "## Install python deps\n",
        "\n",
        "### Subtask:\n",
        "Install the necessary Python dependencies for the data processing pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec1f8cd1"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to install the necessary Python dependencies. The provided code cell `gHNrLqcN7rHk` does exactly this by running `pip install` for a list of required packages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cb2d4c0"
      },
      "source": [
        "!pip -q install pypdf python-docx html2text beautifulsoup4 tiktoken pandas pyarrow openai google-generativeai tqdm\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81a25098"
      },
      "source": [
        "## Set providers\n",
        "\n",
        "### Subtask:\n",
        "Configure the LLM and embedding providers and set API keys for the data processing pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fdfc677"
      },
      "source": [
        "**Reasoning**:\n",
        "The code cell `h3X4o7a78AdF` already contains the code to configure the LLM and embedding providers and print the configuration. I will execute this cell as it directly addresses step 1, 2, and 4 of the instructions. Step 3 is a manual step for the user outside of the code execution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc6bca84",
        "outputId": "69237ef2-29ff-416c-9194-60eed00516e9"
      },
      "source": [
        "import os\n",
        "\n",
        "# ---- Choose providers ----\n",
        "LLM_FOR_CONTEXT = \"openai\"   # options: \"openai\", \"ollama\", \"none\"\n",
        "EMBED_PROVIDER  = \"openai\"   # options: \"openai\", \"google\"\n",
        "\n",
        "# ---- Keys (assume they already exist; just set in the environment in Colab UI) ----\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"...\"       # set in Colab > three-dots > Variables (recommended)\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = \"...\"\n",
        "\n",
        "# ---- Ollama via ngrok (optional). Example: \"https://user:pass-yourname.ngrok-free.app\"\n",
        "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\", \"\").strip()\n",
        "\n",
        "# ---- Chunking knobs ----\n",
        "CHUNK_TOKENS   = 800\n",
        "CHUNK_OVERLAP  = 200\n",
        "\n",
        "# ---- Embedding model names (safe defaults) ----\n",
        "OPENAI_EMBED_MODEL  = \"text-embedding-3-small\"  # solid accuracy, good price\n",
        "GOOGLE_EMBED_MODEL  = \"text-embedding-004\"      # current public model name; adjust if Google updates\n",
        "\n",
        "# ---- LLM for analysis (fast & cheap default) ----\n",
        "OPENAI_MINI_MODEL = \"gpt-4o-mini\"               # swap if you prefer o3-mini or similar\n",
        "OLLAMA_MODEL      = \"llama3.1\"                  # choose your local model tag\n",
        "\n",
        "print(\"Configured:\", {\"LLM_FOR_CONTEXT\": LLM_FOR_CONTEXT, \"EMBED_PROVIDER\": EMBED_PROVIDER})"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configured: {'LLM_FOR_CONTEXT': 'openai', 'EMBED_PROVIDER': 'openai'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b5bde94"
      },
      "source": [
        "## Upload files\n",
        "\n",
        "### Subtask:\n",
        "Upload files to the designated upload directory in the Colab environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6efb6a13"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute the code to upload files to the specified directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "4ea5d149",
        "outputId": "80b70429-b93a-4903-f486-5f5b38864878"
      },
      "source": [
        "from google.colab import files\n",
        "import os, shutil, pathlib\n",
        "\n",
        "UPLOAD_DIR = \"/content/uploads\"\n",
        "pathlib.Path(UPLOAD_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Select one or more filesâ€¦\")\n",
        "up = files.upload()\n",
        "for name, data in up.items():\n",
        "    with open(os.path.join(UPLOAD_DIR, name), \"wb\") as f:\n",
        "        f.write(data)\n",
        "print(\"Saved to\", UPLOAD_DIR, \"->\", os.listdir(UPLOAD_DIR))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select one or more filesâ€¦\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-42b14877-b758-49f3-807e-ace0b5433738\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-42b14877-b758-49f3-807e-ace0b5433738\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Attentionisallyouneed.pdf to Attentionisallyouneed.pdf\n",
            "Saved to /content/uploads -> ['1-bitLLMs.pdf', 'Attentionisallyouneed.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9120c52"
      },
      "source": [
        "## Normalize files to text\n",
        "\n",
        "### Subtask:\n",
        "Normalize the uploaded files to plain text format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ed54bb7"
      },
      "source": [
        "**Reasoning**:\n",
        "The code cell `hVVvmcPn8Yku` contains the necessary functions and logic to convert different file types (PDF, DOCX, HTML, text-like) into plain text and store them in the `docs` variable. I will execute this cell to perform the normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3689c4c6",
        "outputId": "23c0aac0-a6ee-4351-fe3a-06a9c2052c9e"
      },
      "source": [
        "import pathlib, re\n",
        "from pypdf import PdfReader\n",
        "import docx\n",
        "from bs4 import BeautifulSoup\n",
        "import html2text\n",
        "\n",
        "def read_pdf(path: str) -> str:\n",
        "    out = []\n",
        "    try:\n",
        "        pdf = PdfReader(path)\n",
        "        for p in pdf.pages:\n",
        "            out.append(p.extract_text() or \"\")\n",
        "    except Exception as e:\n",
        "        print(f\"[PDF ERROR] {path} -> {e}\")\n",
        "    return \"\\n\".join(out)\n",
        "\n",
        "def read_docx(path: str) -> str:\n",
        "    try:\n",
        "        d = docx.Document(path)\n",
        "        return \"\\n\".join([p.text for p in d.paragraphs])\n",
        "    except Exception as e:\n",
        "        print(f\"[DOCX ERROR] {path} -> {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def read_html(path: str) -> str:\n",
        "    try:\n",
        "        html = pathlib.Path(path).read_text(errors=\"ignore\")\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "        # keep visible text; fallback to markdown\n",
        "        md = html2text.html2text(str(soup))\n",
        "        return md\n",
        "    except Exception as e:\n",
        "        print(f\"[HTML ERROR] {path} -> {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def read_textlike(path: str) -> str:\n",
        "    try:\n",
        "        return pathlib.Path(path).read_text(errors=\"ignore\")\n",
        "    except Exception as e:\n",
        "        print(f\"[TEXT ERROR] {path} -> {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def to_text(path: str) -> str:\n",
        "    ext = pathlib.Path(path).suffix.lower()\n",
        "    if ext == \".pdf\":   return read_pdf(path)\n",
        "    if ext == \".docx\":  return read_docx(path)\n",
        "    if ext in (\".html\", \".htm\"): return read_html(path)\n",
        "    # csv, md, txt and others -> read as text\n",
        "    return read_textlike(path)\n",
        "\n",
        "docs = []\n",
        "for p in sorted(pathlib.Path(UPLOAD_DIR).glob(\"**/*\")):\n",
        "    if p.is_file():\n",
        "        txt = to_text(str(p))\n",
        "        txt = re.sub(r\"[ \\t]+\", \" \", txt)\n",
        "        txt = re.sub(r\"\\n{3,}\", \"\\n\\n\", txt).strip()\n",
        "        if len(txt) > 0:\n",
        "            docs.append({\"doc_id\": p.name, \"path\": str(p), \"text\": txt})\n",
        "len(docs), [d[\"doc_id\"] for d in docs][:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, ['1-bitLLMs.pdf', 'Attentionisallyouneed.pdf'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d87c1b7"
      },
      "source": [
        "## Chunk text by tokens\n",
        "\n",
        "### Subtask:\n",
        "Chunk the normalized text into smaller pieces based on token limits and overlap."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff9064b3"
      },
      "source": [
        "**Reasoning**:\n",
        "The code cell `moaQ2yRI8_aT` defines the `split_by_tokens` function and applies it to the normalized text in the `docs` variable to create tokenized chunks stored in the `records` variable. I will execute this cell to perform the chunking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b55eea5e",
        "outputId": "0a274885-ba87-44d4-9954-36170abb2928"
      },
      "source": [
        "import tiktoken\n",
        "from typing import List, Dict\n",
        "\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")  # robust general encoder\n",
        "\n",
        "def split_by_tokens(text: str, target: int, overlap: int) -> List[str]:\n",
        "    tokens = enc.encode(text)\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        window = tokens[i : i + target]\n",
        "        chunks.append(enc.decode(window))\n",
        "        i += max(1, target - overlap)\n",
        "    return chunks\n",
        "\n",
        "records = []\n",
        "for d in docs:\n",
        "    chs = split_by_tokens(d[\"text\"], CHUNK_TOKENS, CHUNK_OVERLAP)\n",
        "    for idx, ch in enumerate(chs):\n",
        "        records.append({\n",
        "            \"id\": f\"{d['doc_id']}::{idx}\",\n",
        "            \"doc_id\": d[\"doc_id\"],\n",
        "            \"chunk_index\": idx,\n",
        "            \"text\": ch,\n",
        "            \"meta\": {\"source\": d[\"path\"]}\n",
        "        })\n",
        "\n",
        "len(records)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b69b4a84"
      },
      "source": [
        "## Run optional context analysis\n",
        "\n",
        "### Subtask:\n",
        "Perform optional context analysis on the text chunks using the selected LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e05b2ceb"
      },
      "source": [
        "**Reasoning**:\n",
        "The code cell `U9oeEBtP9Cid` contains the logic to perform context analysis on the generated chunks using either OpenAI or Ollama, based on the `LLM_FOR_CONTEXT` variable. I will execute this cell to perform the analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d44087ae",
        "outputId": "21c3ffdb-0cd9-4d2c-803e-bf87684e65f2"
      },
      "source": [
        "import json, requests, math, time\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "def analyze_with_openai(texts, model=OPENAI_MINI_MODEL):\n",
        "    import openai\n",
        "    client = openai.OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "    outs = []\n",
        "    for t in texts:\n",
        "        prompt = (\n",
        "          \"Summarize this chunk in 1-2 sentences. \"\n",
        "          \"Also return 3-6 keywords and a short section title.\\n\\nCHUNK:\\n\" + t\n",
        "        )\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\":\"system\",\"content\":\"Be concise and accurate.\"},\n",
        "                      {\"role\":\"user\",\"content\":prompt}],\n",
        "            temperature=0.2,\n",
        "            max_tokens=200,\n",
        "        )\n",
        "        outs.append(resp.choices[0].message.content)\n",
        "    return outs\n",
        "\n",
        "def analyze_with_ollama(texts, model=OLLAMA_MODEL):\n",
        "    # Requires: OLLAMA_BASE_URL to be reachable (e.g., your ngrok tunnel)\n",
        "    outs = []\n",
        "    for t in texts:\n",
        "        payload = {\n",
        "          \"model\": model,\n",
        "          \"messages\": [\n",
        "            {\"role\":\"system\",\"content\":\"Be concise and accurate.\"},\n",
        "            {\"role\":\"user\",\"content\":\n",
        "              \"Summarize this chunk in 1-2 sentences. \"\n",
        "              \"Also return 3-6 keywords and a short section title.\\n\\nCHUNK:\\n\"+t}\n",
        "          ],\n",
        "          \"stream\": False\n",
        "        }\n",
        "        r = requests.post(f\"{OLLAMA_BASE_URL}/api/chat\", json=payload, timeout=120)\n",
        "        r.raise_for_status()\n",
        "        outs.append(r.json().get(\"message\", {}).get(\"content\", \"\"))\n",
        "    return outs\n",
        "\n",
        "def parse_analysis(s: str) -> dict:\n",
        "    # Accept free-form; try to split; keep it robust\n",
        "    if not s: return {\"summary\":\"\", \"keywords\":[], \"section\":\"\"}\n",
        "    lines = [x.strip() for x in s.splitlines() if x.strip()]\n",
        "    summary = lines[0] if lines else \"\"\n",
        "    # naive keyword/section extraction\n",
        "    kws = []\n",
        "    section = \"\"\n",
        "    for ln in lines[1:]:\n",
        "        low = ln.lower()\n",
        "        if \"keyword\" in low:\n",
        "            kws = [k.strip(\" ,;\") for k in ln.split(\":\")[-1].split(\",\")]\n",
        "        if \"title\" in low or \"section\" in low:\n",
        "            section = ln.split(\":\")[-1].strip()\n",
        "    return {\"summary\": summary, \"keywords\": kws, \"section\": section}\n",
        "\n",
        "if LLM_FOR_CONTEXT in (\"openai\",\"ollama\"):\n",
        "    BATCH = 16\n",
        "    for i in tqdm(range(0, len(records), BATCH)):\n",
        "        batch = records[i:i+BATCH]\n",
        "        texts = [r[\"text\"] for r in batch]\n",
        "        if LLM_FOR_CONTEXT == \"openai\":\n",
        "            outs = analyze_with_openai(texts)\n",
        "        else:\n",
        "            assert OLLAMA_BASE_URL, \"Set OLLAMA_BASE_URL to your ngrok tunnel (e.g., https://user:pass-<name>.ngrok-free.app)\"\n",
        "            outs = analyze_with_ollama(texts)\n",
        "        for r, out in zip(batch, outs):\n",
        "            r.update(parse_analysis(out))\n",
        "else:\n",
        "    print(\"Skipping context analysis.\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:25<00:00, 12.72s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cb0961c"
      },
      "source": [
        "## Generate embeddings\n",
        "\n",
        "### Subtask:\n",
        "Generate embeddings for the text chunks using the selected embedding provider."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c05b085d"
      },
      "source": [
        "**Reasoning**:\n",
        "The code cell `KYqHUIoz9uMK` contains the logic to generate embeddings for the text chunks using either OpenAI or Google embeddings, based on the `EMBED_PROVIDER` variable. I will execute this cell to perform the embedding generation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36572a88",
        "outputId": "f4c52014-8ac7-4b5b-da22-23d2ca2e1ecb"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "\n",
        "def embed_openai(texts):\n",
        "    import openai\n",
        "    client = openai.OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "    # Batch for efficiency\n",
        "    vecs = []\n",
        "    B = 128\n",
        "    for i in tqdm(range(0, len(texts), B)):\n",
        "        sub = texts[i:i+B]\n",
        "        resp = client.embeddings.create(model=OPENAI_EMBED_MODEL, input=sub)\n",
        "        vecs.extend([np.array(d.embedding, dtype=np.float32) for d in resp.data])\n",
        "    return vecs\n",
        "\n",
        "def embed_google(texts):\n",
        "    import google.generativeai as genai\n",
        "    genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "    model = genai.embedder.GenerativeModelEmbedding(  # fallback if class evolves; API sometimes provides simple `genai.embed_content`\n",
        "        model_name=GOOGLE_EMBED_MODEL\n",
        "    ) if hasattr(genai, \"embedder\") else None\n",
        "\n",
        "    vecs = []\n",
        "    for t in tqdm(texts):\n",
        "        # API surface changes over time; this path works with most releases:\n",
        "        if hasattr(genai, \"embed_content\"):\n",
        "            out = genai.embed_content(model=GOOGLE_EMBED_MODEL, content=t)\n",
        "            vecs.append(np.array(out[\"embedding\"], dtype=np.float32))\n",
        "        else:\n",
        "            # future-proof fallback if embedder object exists\n",
        "            out = genai.embedder.embed(model=GOOGLE_EMBED_MODEL, content=t)\n",
        "            vecs.append(np.array(out[\"embedding\"], dtype=np.float32))\n",
        "    return vecs\n",
        "\n",
        "texts = [r[\"text\"] for r in records]\n",
        "if EMBED_PROVIDER == \"openai\":\n",
        "    vectors = embed_openai(texts)\n",
        "else:\n",
        "    vectors = embed_google(texts)\n",
        "\n",
        "for r, v in zip(records, vectors):\n",
        "    r[\"embedding\"] = v.tolist()\n",
        "\n",
        "len(records), len(records[0][\"embedding\"])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 1536)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e2c048d"
      },
      "source": [
        "## Save JSONL/Parquet dataset\n",
        "\n",
        "### Subtask:\n",
        "Save the processed data, including embeddings, to JSONL and Parquet files and provide them for download."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22728151"
      },
      "source": [
        "**Reasoning**:\n",
        "The code cell `0rxKSUTx912d` saves the processed data, including the generated embeddings, to JSONL and Parquet files and then provides download links for these files. This directly addresses the subtask. I will execute this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "a36abe8b",
        "outputId": "65da8cdc-f479-4477-dea8-cc57a8191cd2"
      },
      "source": [
        "import json, pandas as pd, numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# JSONL\n",
        "jsonl_path = \"/content/dataset.jsonl\"\n",
        "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for r in records:\n",
        "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "# Parquet (store embeddings as list or fixed-length numpy array)\n",
        "df = pd.DataFrame(records)\n",
        "parquet_path = \"/content/dataset.parquet\"\n",
        "df.to_parquet(parquet_path, engine=\"pyarrow\", index=False)\n",
        "\n",
        "print(\"Wrote:\", jsonl_path, parquet_path)\n",
        "files.download(jsonl_path)\n",
        "files.download(parquet_path)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /content/dataset.jsonl /content/dataset.parquet\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_eff33145-9688-4f6b-9f91-71828b8dd17d\", \"dataset.jsonl\", 1129673)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_99ab2e3b-e0ee-46a1-879b-523561334bd5\", \"dataset.parquet\", 415295)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}